#!/bin/bash
# Script para executar teste baseline COM RAG + DSPy MANUAL usando CrewAI
# Faz LLM calls reais, executa tasks, cria arquivos, e rastreia TUDO no AgentOps!

echo "================================================================================"
echo "üß™ CrewAI + DSPy Baseline Test - HYBRID APPROACH"
echo "================================================================================"
echo ""
echo "Este script executa 5 projetos usando:"
echo "‚úÖ CrewAI framework (agents, tasks, tools)"
echo "‚úÖ DSPy manual optimization (few-shot examples)"
echo "‚úÖ RAG para contexto"
echo "‚úÖ AgentOps tracking COMPLETO (tools, agents, tasks, LLM, costs)"
echo ""

# Mudar para diret√≥rio raiz do projeto
cd "$(dirname "$0")/.." || exit 1

# Verificar se API key est√° configurada
echo "Verificando configura√ß√£o..."
API_KEY=$(python -c "from dotenv import load_dotenv; import config; load_dotenv(override=True); print(config.OPENAI_API_KEY[:20] if config.OPENAI_API_KEY else 'None')" 2>/dev/null)
if [ "$API_KEY" = "None" ]; then
    echo "‚ùå OPENAI_API_KEY n√£o configurada!"
    echo ""
    echo "Por favor, configure a API key no arquivo .env:"
    echo "  OPENAI_API_KEY=sk-proj-your-key-here"
    echo ""
    exit 1
fi

if [[ $API_KEY == sk-proj* ]] || [[ $API_KEY == sk-* ]]; then
    echo "‚úÖ API Key configurada: ${API_KEY}..."
else
    echo "‚ö†Ô∏è  Formato de API key inesperado: $API_KEY"
    echo "    Continuando mesmo assim..."
fi
echo ""

# Informar sobre configura√ß√£o
echo "‚úÖ RAG: HABILITADO"
echo "üîß DSPy: OTIMIZA√á√ÉO MANUAL (few-shot examples)"
echo "ü§ñ CrewAI: FRAMEWORK COMPLETO (agents, tasks, tools)"
echo "üìä AgentOps: TRACKING COMPLETO"
echo "üí° LLM CALLS: REAIS"
echo ""

# Executar teste
echo "Iniciando teste baseline CrewAI + DSPy..."
echo "Dura√ß√£o estimada: 30-50 minutos (executa tasks completas!)"
echo "Custo estimado: ~\$5.00-10.00"
echo ""

# Limpar API key cache e executar
unset OPENAI_API_KEY
exec python -c "
import os
import sys
import time
import json
from pathlib import Path
from datetime import datetime

# For√ßar reload do .env
from dotenv import load_dotenv
load_dotenv(override=True)

# Add to path
sys.path.insert(0, '.')

# CRITICAL: Import LLM modules BEFORE agentops.init()
# This allows AgentOps to instrument them properly
print('üì¶ Carregando m√≥dulos LLM...')
import openai
import langchain
import langchain_openai
from crewai import Agent, Task, Crew

print('‚úÖ M√≥dulos LLM carregados')

# Import config and dspy
import config
from dspy_config import configure_dspy

print('üì¶ Carregando crew...')

# NOW import and initialize AgentOps BEFORE importing crew
import agentops

agentops_enabled = False
try:
    agentops_key = os.getenv('AGENTOPS_API_KEY')
    if agentops_key:
        print('üîç Inicializando AgentOps...')
        # Initialize with proper instrumentation (like baselines)
        agentops.init(
            api_key=agentops_key,
            default_tags=['baseline', 'crewai-dspy', 'rag', 'hybrid'],
            auto_start_session=True,
            instrument_llm_calls=True,  # ENABLE LLM tracking!
        )
        agentops_enabled = True
        print('‚úÖ AgentOps inicializado')
        print('   üîç LLM Call Tracking: ENABLED')
        print('   üìä Agent/Task/Tool Tracking: ENABLED')
        print()
    else:
        print('‚ö†Ô∏è  AGENTOPS_API_KEY n√£o configurada')
        print()
except Exception as e:
    print(f'‚ö†Ô∏è  AgentOps n√£o dispon√≠vel: {e}')
    print()

# Import crew function AFTER AgentOps is initialized
from crew_crewai_dspy import run_software_dev_crew_dspy

# Projetos de teste
TEST_PROJECTS = [
    {
        'id': 'project_01',
        'name': 'Todo List CLI',
        'description': 'crie uma aplica√ß√£o CLI para gerenciar lista de tarefas com comandos add, list, done e delete'
    },
    {
        'id': 'project_02',
        'name': 'URL Shortener API',
        'description': 'crie uma API REST para encurtar URLs com endpoints para criar, listar e redirecionar'
    },
    {
        'id': 'project_03',
        'name': 'Weather CLI',
        'description': 'crie uma ferramenta CLI que consulta API de clima e mostra previs√£o formatada'
    },
    {
        'id': 'project_04',
        'name': 'Password Generator',
        'description': 'crie um gerador de senhas seguras CLI com op√ß√µes de tamanho, caracteres especiais e for√ßa'
    },
    {
        'id': 'project_05',
        'name': 'Markdown to HTML Converter',
        'description': 'crie um conversor de Markdown para HTML com suporte a t√≠tulos, listas e links'
    },
]

print()
print('=' * 80)
print('üß™ TESTE BASELINE CREWAI + DSPY - BATCH DE 5 PROJETOS')
print('=' * 80)
print()
print('Este teste usa CrewAI COM DSPy otimiza√ß√£o manual.')
print('FAZ LLM CALLS REAIS e executa TASKS COMPLETAS!')
print('Rastreia TUDO no AgentOps: tools, agents, tasks, LLM, costs')
print()

# Configurar DSPy (para RAG)
print('‚öôÔ∏è  Configurando DSPy...')
configure_dspy()
print('‚úÖ DSPy configurado')
print()
print('‚úÖ CrewAI + DSPy + RAG + AgentOps configurado!')
print()

# Listar projetos
print(f'üìã Projetos a serem executados: {len(TEST_PROJECTS)}')
for i, proj in enumerate(TEST_PROJECTS, 1):
    print(f'   {i}. {proj[\"name\"]} ({proj[\"id\"]})')
print()
print('Iniciando em 3 segundos...')
time.sleep(3)
print()

# Executar batch
all_metrics = []
batch_start = time.time()

for i, project in enumerate(TEST_PROJECTS, 1):
    print()
    print('=' * 80)
    print(f'üìã PROJETO {i}/{len(TEST_PROJECTS)}: {project[\"name\"]}')
    print(f'ID: {project[\"id\"]}')
    print('=' * 80)
    print()

    start = time.time()

    try:
        # Executar CrewAI crew com DSPy optimization
        result = run_software_dev_crew_dspy(
            project_idea=project['description']
        )

        duration = time.time() - start

        metrics = {
            'project_id': project['id'],
            'project_name': project['name'],
            'status': 'success',
            'duration_seconds': round(duration, 2),
            'timestamp': datetime.now().isoformat(),
            'approach': 'crewai_dspy_hybrid',
            'note': 'CrewAI framework + DSPy manual few-shot + RAG + AgentOps'
        }

        # Salvar m√©tricas
        metrics_dir = Path('metrics/data/crewai_dspy')
        metrics_dir.mkdir(parents=True, exist_ok=True)
        metrics_file = metrics_dir / f'baseline_{project[\"id\"]}.json'
        metrics_file.write_text(json.dumps(metrics, indent=2))

        print()
        print('=' * 80)
        print(f'‚úÖ PROJETO {i} CONCLU√çDO')
        print('=' * 80)
        print(f'‚è±Ô∏è  Dura√ß√£o: {duration:.2f}s ({duration/60:.1f} min)')
        print()

        all_metrics.append(metrics)

    except Exception as e:
        duration = time.time() - start
        print(f'‚ùå Error: {e}')
        import traceback
        traceback.print_exc()

        all_metrics.append({
            'project_id': project['id'],
            'project_name': project['name'],
            'status': 'error',
            'duration_seconds': round(duration, 2),
            'error': str(e),
            'timestamp': datetime.now().isoformat(),
            'approach': 'crewai_dspy_hybrid'
        })

    # Pausa entre projetos
    if i < len(TEST_PROJECTS):
        print('\\n‚è∏Ô∏è  Aguardando 10 segundos antes do pr√≥ximo projeto...')
        time.sleep(10)

batch_duration = time.time() - batch_start

# Gerar relat√≥rio
total_duration = sum(m['duration_seconds'] for m in all_metrics)
successful = sum(1 for m in all_metrics if m['status'] == 'success')

print()
print('=' * 80)
print('üìä RELAT√ìRIO BASELINE CREWAI + DSPY - RESUMO')
print('=' * 80)
print()
print(f'Total de projetos: {len(all_metrics)}')
print(f'‚úÖ Sucesso: {successful}')
print(f'‚ùå Falhas: {len(all_metrics) - successful}')
print(f'‚è±Ô∏è  Dura√ß√£o total: {total_duration:.2f}s ({total_duration/60:.1f} min)')
print(f'‚è±Ô∏è  Dura√ß√£o m√©dia: {total_duration/len(all_metrics):.2f}s ({total_duration/len(all_metrics)/60:.1f} min) por projeto')
print()

# Salvar relat√≥rio
report_path = Path('metrics/data/crewai_dspy/baseline_report.json')
report = {
    'test_type': 'baseline_crewai_dspy_hybrid',
    'test_date': datetime.now().isoformat(),
    'total_projects': len(all_metrics),
    'successful': successful,
    'failed': len(all_metrics) - successful,
    'total_duration_seconds': round(total_duration, 2),
    'avg_duration_per_project_seconds': round(total_duration/len(all_metrics), 2),
    'projects': all_metrics,
    'approach': {
        'framework': 'CrewAI',
        'optimization': 'DSPy manual few-shot',
        'rag': 'enabled',
        'tracking': 'AgentOps (tools, agents, tasks, LLM, costs)'
    }
}
report_path.write_text(json.dumps(report, indent=2))
print(f'üíæ Relat√≥rio salvo em: {report_path}')

print()
print('=' * 80)
print('üéâ TESTE BASELINE CREWAI + DSPY CONCLU√çDO!')
print('=' * 80)
print()
print('Este teste usou:')
print('‚úÖ CrewAI framework (executa tasks, usa tools, cria arquivos)')
print('‚úÖ DSPy manual optimization (few-shot examples)')
print('‚úÖ RAG para contexto')
print('‚úÖ AgentOps tracking COMPLETO')
print()
print('üìä Verifique o dashboard do AgentOps para m√©tricas completas:')
print('   - Tool calls')
print('   - Agent actions')
print('   - Task execution')
print('   - LLM calls e tokens')
print('   - Costs')
print()

# Finalizar AgentOps
if agentops_enabled:
    print('üìä Finalizando AgentOps session...')
    agentops.end_session(end_state='Success')

sys.exit(0)
"
