#!/usr/bin/env python3
"""
Teste Baseline SEM RAG - Executa 5 projetos em sequ√™ncia
Coleta m√©tricas detalhadas para compara√ß√£o com baseline COM RAG

Este script serve como baseline SEM RAG para estudos comparativos.
"""
import sys
import time
import json
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

load_dotenv(override=True)

# Import ap√≥s carregar env
import openai
import langchain
import langchain_openai
from crewai import Agent, Task, Crew

import agentops
from crew_no_rag import run_software_dev_crew
import config
from metrics import get_tracker, reset_tracker


# 5 projetos de teste para baseline - MESMOS projetos do baseline com RAG
TEST_PROJECTS = [
    {
        "id": "project_01",
        "name": "Todo List CLI",
        "description": "crie uma aplica√ß√£o CLI para gerenciar lista de tarefas com comandos add, list, done e delete",
    },
    {
        "id": "project_02",
        "name": "URL Shortener API",
        "description": "crie uma API REST para encurtar URLs com endpoints para criar, listar e redirecionar",
    },
    {
        "id": "project_03",
        "name": "Weather CLI",
        "description": "crie uma ferramenta CLI que consulta API de clima e mostra previs√£o formatada",
    },
    {
        "id": "project_04",
        "name": "Password Generator",
        "description": "crie um gerador de senhas seguras CLI com op√ß√µes de tamanho, caracteres especiais e for√ßa",
    },
    {
        "id": "project_05",
        "name": "Markdown to HTML Converter",
        "description": "crie um conversor de Markdown para HTML com suporte a t√≠tulos, listas e links",
    },
]


def initialize_observability():
    """Initialize AgentOps if available."""
    if not config.AGENTOPS_API_KEY:
        print("‚ö†Ô∏è  AgentOps n√£o configurado - rodando sem observabilidade")
        return False

    try:
        agentops.init(
            api_key=config.AGENTOPS_API_KEY,
            default_tags=["baseline-no-rag", "batch-run"],
            auto_start_session=True,
            instrument_llm_calls=True,
        )
        print("‚úÖ AgentOps inicializado")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao inicializar AgentOps: {e}")
        return False


def run_single_project(project_info: dict, project_num: int, total: int):
    """
    Executa um √∫nico projeto e coleta m√©tricas.

    Returns:
        dict: M√©tricas do projeto
    """
    print("\n" + "=" * 80)
    print(f"üìã PROJETO {project_num}/{total}: {project_info['name']}")
    print(f"ID: {project_info['id']}")
    print("=" * 80)
    print()

    # Reset tracker para este projeto
    tracker = reset_tracker()
    start_time = time.time()

    try:
        # Executar crew SEM RAG
        result = run_software_dev_crew(project_info['description'])

        # Calcular dura√ß√£o total
        duration = time.time() - start_time

        # Coletar m√©tricas
        summary = tracker.get_summary()

        # Salvar m√©tricas espec√≠ficas deste projeto em diret√≥rio separado
        metrics_file = Path("metrics/data/no_rag") / f"baseline_{project_info['id']}.json"
        metrics_file.parent.mkdir(parents=True, exist_ok=True)

        project_metrics = {
            "project_id": project_info['id'],
            "project_name": project_info['name'],
            "description": project_info['description'],
            "timestamp": datetime.now().isoformat(),
            "duration_seconds": duration,
            "status": "success",
            "rag_enabled": False,  # Importante: marcar que RAG N√ÉO est√° habilitado
            "metrics": summary,
        }

        metrics_file.write_text(json.dumps(project_metrics, indent=2))

        print()
        print("=" * 80)
        print(f"‚úÖ PROJETO {project_num} CONCLU√çDO")
        print("=" * 80)
        print(f"‚è±Ô∏è  Dura√ß√£o: {duration:.2f}s")
        print(f"üí∞ Custo: ${summary['summary']['total_cost']:.4f}")
        print(f"üé´ Tokens: {summary['summary']['total_tokens']:,}")
        print(f"üìä LLM Calls: {summary['summary']['total_llm_calls']}")
        print()

        return project_metrics

    except Exception as e:
        print(f"\n‚ùå ERRO no projeto {project_num}: {e}")
        duration = time.time() - start_time

        error_metrics = {
            "project_id": project_info['id'],
            "project_name": project_info['name'],
            "description": project_info['description'],
            "timestamp": datetime.now().isoformat(),
            "duration_seconds": duration,
            "status": "failed",
            "rag_enabled": False,
            "error": str(e),
            "metrics": None,
        }

        return error_metrics


def generate_baseline_report(all_metrics: list, batch_duration: float):
    """
    Gera relat√≥rio consolidado do baseline SEM RAG.

    Args:
        all_metrics: Lista de m√©tricas de todos os projetos
        batch_duration: Dura√ß√£o total do batch
    """
    print("\n" + "=" * 80)
    print("üìä RELAT√ìRIO BASELINE SEM RAG - RESUMO CONSOLIDADO")
    print("=" * 80)
    print()

    # Filtrar sucessos e falhas
    successful = [m for m in all_metrics if m['status'] == 'success']
    failed = [m for m in all_metrics if m['status'] == 'failed']

    print(f"Total de projetos: {len(all_metrics)}")
    print(f"‚úÖ Sucesso: {len(successful)}")
    print(f"‚ùå Falhas: {len(failed)}")
    print(f"‚è±Ô∏è  Dura√ß√£o total: {batch_duration:.2f}s ({batch_duration/60:.1f} min)")
    print()

    if not successful:
        print("‚ö†Ô∏è  Nenhum projeto conclu√≠do com sucesso")
        return

    # Calcular estat√≠sticas agregadas
    total_cost = sum(m['metrics']['summary']['total_cost'] for m in successful)
    total_tokens = sum(m['metrics']['summary']['total_tokens'] for m in successful)
    total_llm_calls = sum(m['metrics']['summary']['total_llm_calls'] for m in successful)
    avg_duration = sum(m['duration_seconds'] for m in successful) / len(successful)

    print("--- ESTAT√çSTICAS AGREGADAS (SEM RAG) ---")
    print(f"üí∞ Custo total: ${total_cost:.4f}")
    print(f"üí∞ Custo m√©dio por projeto: ${total_cost/len(successful):.4f}")
    print(f"üé´ Tokens totais: {total_tokens:,}")
    print(f"üé´ Tokens m√©dios por projeto: {total_tokens//len(successful):,}")
    print(f"üìû LLM calls totais: {total_llm_calls}")
    print(f"üìû LLM calls m√©dias: {total_llm_calls//len(successful)}")
    print(f"‚è±Ô∏è  Dura√ß√£o m√©dia por projeto: {avg_duration:.2f}s")
    print()

    print("--- DETALHES POR PROJETO ---")
    for i, metrics in enumerate(successful, 1):
        print(f"\n{i}. {metrics['project_name']} ({metrics['project_id']})")
        print(f"   Status: {metrics['status']}")
        print(f"   Dura√ß√£o: {metrics['duration_seconds']:.2f}s")
        print(f"   Custo: ${metrics['metrics']['summary']['total_cost']:.4f}")
        print(f"   Tokens: {metrics['metrics']['summary']['total_tokens']:,}")
        print(f"   LLM calls: {metrics['metrics']['summary']['total_llm_calls']}")

    if failed:
        print("\n--- PROJETOS COM FALHA ---")
        for i, metrics in enumerate(failed, 1):
            print(f"\n{i}. {metrics['project_name']} ({metrics['project_id']})")
            print(f"   Erro: {metrics['error']}")
            print(f"   Dura√ß√£o antes da falha: {metrics['duration_seconds']:.2f}s")

    # Salvar relat√≥rio consolidado em diret√≥rio separado
    report_path = Path("metrics/data/no_rag/baseline_report.json")
    report_path.parent.mkdir(parents=True, exist_ok=True)

    consolidated_report = {
        "report_type": "baseline_no_rag",
        "rag_enabled": False,
        "timestamp": datetime.now().isoformat(),
        "batch_duration_seconds": batch_duration,
        "total_projects": len(all_metrics),
        "successful_projects": len(successful),
        "failed_projects": len(failed),
        "aggregated_stats": {
            "total_cost": total_cost,
            "avg_cost_per_project": total_cost / len(successful) if successful else 0,
            "total_tokens": total_tokens,
            "avg_tokens_per_project": total_tokens // len(successful) if successful else 0,
            "total_llm_calls": total_llm_calls,
            "avg_llm_calls_per_project": total_llm_calls // len(successful) if successful else 0,
            "total_rag_retrievals": 0,  # Zero para baseline sem RAG
            "avg_duration_per_project": avg_duration if successful else 0,
        },
        "projects": all_metrics,
    }

    report_path.write_text(json.dumps(consolidated_report, indent=2))
    print(f"\nüíæ Relat√≥rio consolidado salvo em: {report_path}")
    print()


def main():
    """Executa teste baseline SEM RAG completo."""
    print()
    print("=" * 80)
    print("üß™ TESTE BASELINE SEM RAG - BATCH DE 5 PROJETOS")
    print("=" * 80)
    print()
    print("Este teste executa 5 projetos SEM RAG em sequ√™ncia.")
    print("M√©tricas coletadas servir√£o como compara√ß√£o com baseline COM RAG.")
    print()

    # Verificar API key
    if not config.OPENAI_API_KEY:
        print("‚ùå OPENAI_API_KEY n√£o configurada!")
        print("   Configure no arquivo .env antes de executar.")
        return 1

    print(f"‚úÖ API Key configurada")
    print()

    # Inicializar sistemas
    observability_enabled = initialize_observability()
    print("üö´ RAG DESABILITADO (baseline sem RAG)")
    print()

    # Confirmar execu√ß√£o
    print(f"üìã Projetos a serem executados: {len(TEST_PROJECTS)}")
    for i, proj in enumerate(TEST_PROJECTS, 1):
        print(f"   {i}. {proj['name']} ({proj['id']})")
    print()

    input("Pressione ENTER para iniciar ou Ctrl+C para cancelar...")
    print()

    # Executar batch
    batch_start = time.time()
    all_metrics = []

    try:
        for i, project in enumerate(TEST_PROJECTS, 1):
            metrics = run_single_project(project, i, len(TEST_PROJECTS))
            all_metrics.append(metrics)

            # Pequena pausa entre projetos
            if i < len(TEST_PROJECTS):
                print("\n‚è∏Ô∏è  Aguardando 5 segundos antes do pr√≥ximo projeto...")
                time.sleep(5)

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Teste interrompido pelo usu√°rio")
        if observability_enabled:
            agentops.end_session(end_state="Indeterminate")
        return 130

    batch_duration = time.time() - batch_start

    # Gerar relat√≥rio
    generate_baseline_report(all_metrics, batch_duration)

    # Finalizar observability
    if observability_enabled:
        agentops.end_session(end_state="Success")

    print()
    print("=" * 80)
    print("üéâ TESTE BASELINE SEM RAG CONCLU√çDO!")
    print("=" * 80)
    print()
    print("Pr√≥ximos passos:")
    print("  1. Revise o relat√≥rio em metrics/data/no_rag/baseline_report.json")
    print("  2. Compare com baseline COM RAG em metrics/data/baseline_report.json")
    print("  3. Use scripts/compare_baselines.py para an√°lise comparativa")
    print()

    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
