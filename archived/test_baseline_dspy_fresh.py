#!/usr/bin/env python3
"""
Teste baseline COM RAG + DSPy (Pipeline Fresh - LLM Calls Reais).
Usa agentes DSPy otimizados MAS sem demos pr√©-compiladas.
Faz LLM calls reais e gera m√©tricas reais.
"""
import sys
import time
import json
from pathlib import Path
from datetime import datetime

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

import config
from crew_dspy import SoftwareDevPipeline, save_pipeline_outputs
from dspy_config import configure_dspy

# Projetos de teste
TEST_PROJECTS = [
    {
        "id": "project_01",
        "name": "Todo List CLI",
        "description": "crie uma aplica√ß√£o CLI para gerenciar lista de tarefas com comandos add, list, done e delete"
    },
    {
        "id": "project_02",
        "name": "URL Shortener API",
        "description": "crie uma API REST para encurtar URLs com endpoints para criar, listar e redirecionar"
    },
    {
        "id": "project_03",
        "name": "Weather CLI",
        "description": "crie uma ferramenta CLI que consulta API de clima e mostra previs√£o formatada"
    },
    {
        "id": "project_04",
        "name": "Password Generator",
        "description": "crie um gerador de senhas seguras CLI com op√ß√µes de tamanho, caracteres especiais e for√ßa"
    },
    {
        "id": "project_05",
        "name": "Markdown to HTML Converter",
        "description": "crie um conversor de Markdown para HTML com suporte a t√≠tulos, listas e links"
    },
]


def initialize_observability():
    """Inicializa AgentOps se dispon√≠vel."""
    try:
        import agentops
        if config.AGENTOPS_API_KEY:
            agentops.init(
                api_key=config.AGENTOPS_API_KEY,
                tags=["baseline", "dspy-fresh", "rag"]
            )
            print("‚úÖ AgentOps inicializado")
            return True
        else:
            print("‚ö†Ô∏è  AgentOps API key n√£o configurada")
            return False
    except Exception as e:
        print(f"‚ö†Ô∏è  AgentOps n√£o dispon√≠vel: {e}")
        return False


def run_single_project(project: dict, index: int, total: int, pipeline: SoftwareDevPipeline) -> dict:
    """
    Executa um √∫nico projeto e coleta m√©tricas.

    Args:
        project: Dicion√°rio com informa√ß√µes do projeto
        index: √çndice do projeto (1-based)
        total: Total de projetos
        pipeline: Pipeline DSPy fresh (sem otimiza√ß√£o)

    Returns:
        Dicion√°rio com m√©tricas do projeto
    """
    print()
    print("=" * 80)
    print(f"üìã PROJETO {index}/{total}: {project['name']}")
    print(f"ID: {project['id']}")
    print("=" * 80)
    print()

    start_time = time.time()

    try:
        # Executar pipeline DSPy fresh (faz LLM calls reais!)
        result = pipeline(project_idea=project['description'])

        # Salvar outputs
        save_pipeline_outputs(result, project['description'])

        duration = time.time() - start_time

        # M√©tricas b√°sicas (AgentOps trackeia LLM calls automaticamente)
        metrics = {
            "project_id": project['id'],
            "project_name": project['name'],
            "status": "success",
            "duration_seconds": round(duration, 2),
            "cost_usd": 0.0,  # AgentOps trackeia custo
            "tokens_used": 0,  # AgentOps trackeia tokens
            "llm_calls": 0,  # AgentOps trackeia calls
            "timestamp": datetime.now().isoformat(),
            "note": "Metrics tracked by AgentOps - check dashboard"
        }

        # Salvar m√©tricas individuais
        metrics_dir = Path("metrics/data/dspy_fresh")
        metrics_dir.mkdir(parents=True, exist_ok=True)

        metrics_file = metrics_dir / f"baseline_{project['id']}.json"
        metrics_file.write_text(json.dumps(metrics, indent=2))

        print()
        print("=" * 80)
        print(f"‚úÖ PROJETO {index} CONCLU√çDO")
        print("=" * 80)
        print(f"‚è±Ô∏è  Dura√ß√£o: {duration:.2f}s")
        print(f"üí∞ Custo: ${metrics['cost_usd']:.4f}")
        print(f"üé´ Tokens: {metrics['tokens_used']}")
        print(f"üìä LLM Calls: {metrics['llm_calls']}")
        print()

        return metrics

    except Exception as e:
        duration = time.time() - start_time

        print()
        print("=" * 80)
        print(f"‚ùå PROJETO {index} FALHOU")
        print("=" * 80)
        print(f"Erro: {e}")
        print()

        import traceback
        traceback.print_exc()

        return {
            "project_id": project['id'],
            "project_name": project['name'],
            "status": "error",
            "duration_seconds": round(duration, 2),
            "cost_usd": 0.0,
            "tokens_used": 0,
            "llm_calls": 0,
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
        }


def generate_consolidated_report(all_metrics: list) -> None:
    """Gera relat√≥rio consolidado de todos os projetos."""

    # Calcular estat√≠sticas
    total_projects = len(all_metrics)
    successful = sum(1 for m in all_metrics if m['status'] == 'success')
    failed = total_projects - successful

    total_duration = sum(m['duration_seconds'] for m in all_metrics)
    total_cost = sum(m['cost_usd'] for m in all_metrics)
    total_tokens = sum(m['tokens_used'] for m in all_metrics)
    total_llm_calls = sum(m['llm_calls'] for m in all_metrics)

    avg_duration = total_duration / total_projects if total_projects > 0 else 0
    avg_cost = total_cost / total_projects if total_projects > 0 else 0
    avg_tokens = total_tokens / total_projects if total_projects > 0 else 0
    avg_llm_calls = total_llm_calls / total_projects if total_projects > 0 else 0

    print()
    print("=" * 80)
    print("üìä RELAT√ìRIO BASELINE COM RAG + DSPy (FRESH) - RESUMO CONSOLIDADO")
    print("=" * 80)
    print()
    print(f"Total de projetos: {total_projects}")
    print(f"‚úÖ Sucesso: {successful}")
    print(f"‚ùå Falhas: {failed}")
    print(f"‚è±Ô∏è  Dura√ß√£o total: {total_duration:.2f}s ({total_duration/60:.1f} min)")
    print()
    print("--- ESTAT√çSTICAS AGREGADAS (COM RAG + DSPy FRESH) ---")
    print(f"üí∞ Custo total: ${total_cost:.4f}")
    print(f"üí∞ Custo m√©dio por projeto: ${avg_cost:.4f}")
    print(f"üé´ Tokens totais: {total_tokens}")
    print(f"üé´ Tokens m√©dios por projeto: {int(avg_tokens)}")
    print(f"üìû LLM calls totais: {total_llm_calls}")
    print(f"üìû LLM calls m√©dias: {int(avg_llm_calls)}")
    print(f"‚è±Ô∏è  Dura√ß√£o m√©dia por projeto: {avg_duration:.2f}s")
    print()
    print("--- DETALHES POR PROJETO ---")
    print()

    for i, metrics in enumerate(all_metrics, 1):
        status_icon = "‚úÖ" if metrics['status'] == 'success' else "‚ùå"
        print(f"{i}. {metrics['project_name']} ({metrics['project_id']})")
        print(f"   Status: {status_icon} {metrics['status']}")
        print(f"   Dura√ß√£o: {metrics['duration_seconds']:.2f}s")
        print(f"   Custo: ${metrics['cost_usd']:.4f}")
        print(f"   Tokens: {metrics['tokens_used']}")
        print(f"   LLM calls: {metrics['llm_calls']}")
        if 'error' in metrics:
            print(f"   Erro: {metrics['error']}")
        print()

    # Salvar relat√≥rio consolidado
    report_path = Path("metrics/data/dspy_fresh/baseline_report.json")
    report_path.parent.mkdir(parents=True, exist_ok=True)

    consolidated_report = {
        "test_type": "baseline_dspy_fresh",
        "test_date": datetime.now().isoformat(),
        "total_projects": total_projects,
        "successful": successful,
        "failed": failed,
        "total_duration_seconds": round(total_duration, 2),
        "aggregated_metrics": {
            "total_cost_usd": round(total_cost, 4),
            "avg_cost_per_project_usd": round(avg_cost, 4),
            "total_tokens": total_tokens,
            "avg_tokens_per_project": int(avg_tokens),
            "total_llm_calls": total_llm_calls,
            "avg_llm_calls_per_project": int(avg_llm_calls),
            "avg_duration_per_project_seconds": round(avg_duration, 2),
        },
        "projects": all_metrics,
    }

    report_path.write_text(json.dumps(consolidated_report, indent=2))
    print(f"üíæ Relat√≥rio consolidado salvo em: {report_path}")
    print()


def main():
    """Executa teste baseline COM RAG + DSPy fresh completo."""
    print()
    print("=" * 80)
    print("üß™ TESTE BASELINE COM RAG + DSPy (FRESH - LLM CALLS REAIS)")
    print("=" * 80)
    print()
    print("Este teste usa agentes DSPy COM RAG fazendo LLM calls reais.")
    print("ATEN√á√ÉO: N√£o usa pipeline otimizado, faz chamadas LLM reais!")
    print()

    # Verificar API key
    if not config.OPENAI_API_KEY:
        print("‚ùå OPENAI_API_KEY n√£o configurada!")
        print("   Configure no arquivo .env antes de executar.")
        return 1

    print(f"‚úÖ API Key configurada")
    print()

    # Configurar DSPy
    print("‚öôÔ∏è  Configurando DSPy...")
    configure_dspy()
    print()

    # Criar pipeline FRESH (sem demos pr√©-compiladas)
    print("üèóÔ∏è  Criando pipeline DSPy fresh (sem otimiza√ß√£o)...")
    fresh_pipeline = SoftwareDevPipeline()
    print("‚úÖ Pipeline fresh criado - far√° LLM calls reais!")
    print()

    # Inicializar sistemas
    observability_enabled = initialize_observability()
    print("‚úÖ RAG HABILITADO + DSPy FRESH (LLM calls reais)")
    print()

    # Confirmar execu√ß√£o
    print(f"üìã Projetos a serem executados: {len(TEST_PROJECTS)}")
    for i, proj in enumerate(TEST_PROJECTS, 1):
        print(f"   {i}. {proj['name']} ({proj['id']})")
    print()

    # Skip confirmation if --yes flag is provided
    if "--yes" not in sys.argv and "-y" not in sys.argv:
        input("Pressione ENTER para iniciar ou Ctrl+C para cancelar...")
    print()

    # Executar batch
    batch_start = time.time()
    all_metrics = []

    try:
        for i, project in enumerate(TEST_PROJECTS, 1):
            metrics = run_single_project(project, i, len(TEST_PROJECTS), fresh_pipeline)
            all_metrics.append(metrics)

            # Pequena pausa entre projetos
            if i < len(TEST_PROJECTS):
                print("\n‚è∏Ô∏è  Aguardando 5 segundos antes do pr√≥ximo projeto...")
                time.sleep(5)

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Teste interrompido pelo usu√°rio")
        if observability_enabled:
            import agentops
            agentops.end_session(end_state="Indeterminate")
        return 1

    batch_duration = time.time() - batch_start

    # Gerar relat√≥rio consolidado
    generate_consolidated_report(all_metrics)

    # Finalizar observability
    if observability_enabled:
        try:
            import agentops
            agentops.end_session(end_state="Success")
        except:
            pass

    print()
    print("=" * 80)
    print("üéâ TESTE BASELINE COM RAG + DSPy (FRESH) CONCLU√çDO!")
    print("=" * 80)
    print()
    print("Pr√≥ximos passos:")
    print("  1. Revise o relat√≥rio em metrics/data/dspy_fresh/baseline_report.json")
    print("  2. Compare com outros baselines")
    print()

    return 0


if __name__ == "__main__":
    sys.exit(main())
