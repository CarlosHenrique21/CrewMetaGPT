# ğŸ“Š ComparaÃ§Ã£o de Baselines: COM RAG vs SEM RAG

## VisÃ£o Geral

Este documento descreve o processo de comparaÃ§Ã£o entre dois baselines do sistema CrewAI:
- **Baseline COM RAG**: Sistema com Retrieval-Augmented Generation habilitado
- **Baseline SEM RAG**: Sistema usando apenas conhecimento do LLM

## ğŸ¯ Objetivo

Medir o impacto quantitativo do RAG no sistema CrewAI atravÃ©s de mÃ©tricas objetivas:
- **Custo** ($): Quanto custa executar cada configuraÃ§Ã£o
- **Tokens**: Quantos tokens sÃ£o consumidos
- **Performance** (tempo): Quanto tempo leva para executar
- **LLM Calls**: Quantas chamadas sÃ£o feitas ao LLM
- **RAG Retrievals**: Quantas buscas no knowledge base sÃ£o feitas (apenas COM RAG)

## ğŸ“ Estrutura de Arquivos

### Arquivos COM RAG (Original)
```
# CÃ³digo
agents.py                    # Agentes COM RAG tools
tasks.py                     # Tasks usando agents.py
crew.py                      # Crew usando tasks.py

# Teste
tests/test_baseline.py       # Teste baseline COM RAG

# Script
scripts/run_baseline_test.sh # Executa teste COM RAG

# MÃ©tricas
metrics/data/
â”œâ”€â”€ baseline_report.json               # RelatÃ³rio consolidado
â””â”€â”€ baseline_project_*.json            # MÃ©tricas por projeto
```

### Arquivos SEM RAG (Novos)
```
# CÃ³digo
agents_no_rag.py             # Agentes SEM RAG tools
tasks_no_rag.py              # Tasks usando agents_no_rag.py
crew_no_rag.py               # Crew usando tasks_no_rag.py

# Teste
tests/test_baseline_no_rag.py # Teste baseline SEM RAG

# Script
scripts/run_baseline_no_rag.sh # Executa teste SEM RAG

# MÃ©tricas
metrics/data/no_rag/
â”œâ”€â”€ baseline_report.json              # RelatÃ³rio consolidado
â””â”€â”€ baseline_project_*.json           # MÃ©tricas por projeto
```

### Arquivos de ComparaÃ§Ã£o
```
# Script de comparaÃ§Ã£o
scripts/compare_baselines.py  # Compara os dois baselines

# RelatÃ³rio de comparaÃ§Ã£o
metrics/data/comparison_report.json  # AnÃ¡lise comparativa
```

## ğŸ”„ DiferenÃ§as entre as VersÃµes

### agents.py vs agents_no_rag.py

**COM RAG (agents.py):**
```python
from rag import retrieve_context_tool, semantic_search_tool

def create_product_manager() -> Agent:
    return Agent(
        role="Product Manager",
        backstory="""...
        IMPORTANT: Before creating the PRD, use the retrieve_context tool
        to search the knowledge base for similar projects...""",
        tools=[
            file_writer_tool,
            retrieve_context_tool,     # RAG tool
            semantic_search_tool,      # RAG tool
        ],
    )
```

**SEM RAG (agents_no_rag.py):**
```python
# Sem importaÃ§Ãµes de RAG

def create_product_manager() -> Agent:
    return Agent(
        role="Product Manager",
        backstory="""...""",  # Sem instruÃ§Ãµes de RAG
        tools=[
            file_writer_tool,
            # Sem RAG tools
        ],
    )
```

### Principais DiferenÃ§as:

| Aspecto | COM RAG | SEM RAG |
|---------|---------|---------|
| **RAG Tools** | âœ… retrieve_context, semantic_search | âŒ NÃ£o incluÃ­do |
| **Backstory** | âœ… InstruÃ§Ãµes para usar RAG | âŒ Sem instruÃ§Ãµes RAG |
| **Knowledge Base** | âœ… Acessa 5 documentos | âŒ NÃ£o acessa |
| **Context Retrieval** | âœ… Busca semÃ¢ntica habilitada | âŒ Apenas LLM knowledge |
| **Knowledge Manager** | âœ… Agente dedicado | âŒ NÃ£o existe |

## ğŸš€ Como Executar os Baselines

### Passo 1: Executar Baseline COM RAG

```bash
# Executar teste
./scripts/run_baseline_test.sh

# Verificar resultados
cat metrics/data/baseline_report.json | python -m json.tool
```

**DuraÃ§Ã£o estimada:** 10-15 minutos
**Custo estimado:** ~$1.50-3.00

### Passo 2: Executar Baseline SEM RAG

```bash
# Executar teste
./scripts/run_baseline_no_rag.sh

# Verificar resultados
cat metrics/data/no_rag/baseline_report.json | python -m json.tool
```

**DuraÃ§Ã£o estimada:** 10-15 minutos
**Custo estimado:** ~$1.50-3.00

### Passo 3: Comparar os Baselines

```bash
# Executar comparaÃ§Ã£o
python scripts/compare_baselines.py

# Ver relatÃ³rio de comparaÃ§Ã£o
cat metrics/data/comparison_report.json | python -m json.tool
```

## ğŸ“Š Estrutura dos RelatÃ³rios

### RelatÃ³rio Individual (baseline_report.json)

```json
{
  "report_type": "baseline" ou "baseline_no_rag",
  "rag_enabled": true ou false,
  "timestamp": "2025-01-12T...",
  "total_projects": 5,
  "successful_projects": 5,
  "aggregated_stats": {
    "total_cost": 2.5430,
    "avg_cost_per_project": 0.5086,
    "total_tokens": 85340,
    "avg_tokens_per_project": 17068,
    "total_llm_calls": 125,
    "avg_llm_calls_per_project": 25,
    "total_rag_retrievals": 45,  // Apenas COM RAG
    "avg_duration_per_project": 144.1
  },
  "projects": [...]
}
```

### RelatÃ³rio de ComparaÃ§Ã£o (comparison_report.json)

```json
{
  "timestamp": "2025-01-12T...",
  "baseline_with_rag": {
    "stats": {...}
  },
  "baseline_without_rag": {
    "stats": {...}
  },
  "comparison": {
    "cost": {
      "with_rag": 2.5430,
      "without_rag": 2.3200,
      "difference_percent": 9.61,
      "impact": "increase"
    },
    "tokens": {...},
    "duration": {...},
    "llm_calls": {...}
  }
}
```

## ğŸ“ˆ MÃ©tricas Analisadas

### 1. Custo ($)
- **Total Cost**: Custo total de todos os projetos
- **Avg Cost per Project**: Custo mÃ©dio por projeto
- **ComparaÃ§Ã£o**: % de diferenÃ§a entre COM e SEM RAG

### 2. Tokens
- **Total Tokens**: Tokens totais consumidos
- **Avg Tokens per Project**: MÃ©dia de tokens por projeto
- **ComparaÃ§Ã£o**: % de diferenÃ§a entre COM e SEM RAG

### 3. Performance (Tempo)
- **Avg Duration per Project**: Tempo mÃ©dio de execuÃ§Ã£o
- **Batch Duration**: Tempo total do batch
- **ComparaÃ§Ã£o**: % de diferenÃ§a entre COM e SEM RAG

### 4. LLM Calls
- **Total LLM Calls**: Total de chamadas ao LLM
- **Avg LLM Calls**: MÃ©dia de chamadas por projeto
- **ComparaÃ§Ã£o**: % de diferenÃ§a entre COM e SEM RAG

### 5. RAG Retrievals (apenas COM RAG)
- **Total RAG Retrievals**: Total de buscas no knowledge base
- **Avg per Project**: MÃ©dia de retrievals por projeto

## ğŸ” Output do Script de ComparaÃ§Ã£o

O script `compare_baselines.py` gera output formatado com:

### SeÃ§Ãµes:

1. **InformaÃ§Ãµes dos Testes**
   - Data de execuÃ§Ã£o
   - Projetos executados
   - DuraÃ§Ã£o total

2. **ComparaÃ§Ã£o de Custos** ğŸ’°
   - Custo total e mÃ©dio
   - DiferenÃ§a percentual
   - Indicador visual (ğŸ“ˆ/ğŸ“‰)

3. **ComparaÃ§Ã£o de Tokens** ğŸ«
   - Tokens totais e mÃ©dios
   - DiferenÃ§a percentual
   - Indicador visual

4. **ComparaÃ§Ã£o de LLM Calls** ğŸ“
   - Calls totais e mÃ©dias
   - DiferenÃ§a percentual
   - Indicador visual

5. **ComparaÃ§Ã£o de Performance** â±ï¸
   - DuraÃ§Ã£o mÃ©dia por projeto
   - DiferenÃ§a percentual
   - Indicador visual

6. **MÃ©tricas RAG** ğŸ”
   - Total de retrievals (apenas COM RAG)
   - MÃ©dia por projeto

7. **ComparaÃ§Ã£o Detalhada por Projeto** ğŸ“‹
   - ComparaÃ§Ã£o lado a lado de cada projeto
   - Todas as mÃ©tricas por projeto

8. **Resumo Executivo** ğŸ“ˆ
   - Impacto geral do RAG
   - ConclusÃµes por mÃ©trica

## ğŸ“ Projetos de Teste

Os mesmos 5 projetos sÃ£o usados em ambos os baselines:

1. **Todo List CLI** - AplicaÃ§Ã£o CLI para gerenciar tarefas
2. **URL Shortener API** - API REST para encurtar URLs
3. **Weather CLI** - Ferramenta CLI de previsÃ£o do tempo
4. **Password Generator** - Gerador de senhas seguras
5. **Markdown to HTML Converter** - Conversor Markdown para HTML

## ğŸ¯ InterpretaÃ§Ã£o dos Resultados

### Indicadores de Impacto:

- **< 5% de diferenÃ§a**: NEUTRO - Impacto mÃ­nimo
- **5-20% de diferenÃ§a**: MODERADO - Impacto visÃ­vel
- **> 20% de diferenÃ§a**: SIGNIFICATIVO - Impacto alto

### SÃ­mbolos:

- ğŸ“ˆ = Aumento (RAG maior que sem RAG)
- ğŸ“‰ = ReduÃ§Ã£o (RAG menor que sem RAG)
- = = Neutro (< 0.01% diferenÃ§a)

### CenÃ¡rios Esperados:

#### CenÃ¡rio 1: RAG Aumenta Custos/Tokens
- **Causa**: Contexto adicional recuperado do knowledge base
- **Trade-off**: Maior qualidade vs maior custo
- **DecisÃ£o**: Vale a pena se qualidade melhorar significativamente

#### CenÃ¡rio 2: RAG Reduz Custos/Tokens
- **Causa**: Respostas mais diretas com contexto relevante
- **BenefÃ­cio**: Melhor eficiÃªncia com contexto adequado
- **DecisÃ£o**: Win-win (melhor qualidade E menor custo)

#### CenÃ¡rio 3: RAG Neutro em Custos
- **Causa**: Custos de retrieval compensados por respostas mais eficientes
- **BenefÃ­cio**: Melhor qualidade sem custo adicional
- **DecisÃ£o**: Claramente benÃ©fico

## ğŸ”§ Troubleshooting

### Erro: RelatÃ³rio nÃ£o encontrado

```bash
# Verificar se os testes foram executados
ls -la metrics/data/baseline_report.json
ls -la metrics/data/no_rag/baseline_report.json

# Se nÃ£o existirem, executar:
./scripts/run_baseline_test.sh        # COM RAG
./scripts/run_baseline_no_rag.sh      # SEM RAG
```

### Erro: Projetos diferentes

Os dois baselines DEVEM usar os mesmos projetos. Verifique:
```python
# Em tests/test_baseline.py e tests/test_baseline_no_rag.py
TEST_PROJECTS = [...]  # Devem ser idÃªnticos
```

### Erro: ComparaÃ§Ã£o invÃ¡lida

Se os baselines foram executados em momentos muito diferentes:
- Modelos podem ter mudado
- Custos podem ter mudado
- Re-execute ambos os baselines no mesmo dia

## ğŸ“š ReferÃªncias

- **Baseline COM RAG**: [BASELINE_TEST_GUIDE.md](./BASELINE_TEST_GUIDE.md)
- **RAG Integration**: [RAG_INTEGRATION.md](./RAG_INTEGRATION.md)
- **Plano de Estudo**: [PLANO_ESTUDO_RAG_METRICAS.md](./PLANO_ESTUDO_RAG_METRICAS.md)

## ğŸš¦ PrÃ³ximos Passos

1. âœ… Executar baseline COM RAG
2. âœ… Executar baseline SEM RAG
3. âœ… Comparar resultados
4. â³ Analisar qualidade dos outputs (manual)
5. â³ Decidir se RAG vale a pena
6. â³ Otimizar RAG (se necessÃ¡rio)
7. â³ Repetir testes com otimizaÃ§Ãµes

## ğŸ“Œ Notas Importantes

### Isolamento dos Testes
- Cada baseline usa arquivos separados (agents, tasks, crew)
- MÃ©tricas sÃ£o salvas em diretÃ³rios separados
- Nenhum baseline interfere no outro

### Reprodutibilidade
- Mesmos projetos
- Mesmo modelo (gpt-4o-mini)
- Mesmas configuraÃ§Ãµes (max_rpm, verbose, etc)
- Diferentes apenas em RAG tools

### LimitaÃ§Ãµes
- **MÃ©tricas quantitativas apenas**: NÃ£o mede qualidade dos outputs
- **Variabilidade LLM**: Respostas podem variar entre execuÃ§Ãµes
- **Rate limits**: Aguarde 5s entre projetos para evitar rate limits

---

**Ãšltima atualizaÃ§Ã£o**: 2025-01-12
**VersÃ£o**: 1.0
